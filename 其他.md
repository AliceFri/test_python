### 一次僵尸进程的排查
    ps aux | grep Z | wc -l
    1.  子进程是父进程的副本，子进程拥有父进程数据空间、堆、栈的复制副本 ，
        fork 采用了 copy-on-write 技术，fork 操作几乎瞬间可以完成。只有在子进程修改了相应的区域才会进行真正的拷贝。

    2.  一个父进程已经终止的进程被称为孤儿进程（orphan process）。
        操作系统这个大家长是比较人性化的，没有人管的孤儿进程会被进程 ID 为 1 的进程接管。

    3.  父进程负责生，如果不负责养，那就不是一个好父亲。子进程挂了，
        如果父进程不给子进程“收尸”（调用 wait/waitpid），那这个子进程小可怜就变成了僵尸进程。

    4.  1 号进程
        一个进程的父进程退出了，那么这个 init 进程便会接管这个孤儿进程。
        如果一个进程的父进程未执行 wait/waitpid 就退出了，init 进程会接管子进程并自动调用 wait 方法，
        从而保证系统中的僵尸进程可以被移除。

    5.  容器中不合适的 1 号进程 无法回收僵尸进程

    6.  解决方法， 
        1. 让 bash 成为顶层进程
        # CMD ["npm", "run", "start"]
        CMD ["/bin/bash", "-c", "set -e && npm run start"] 
        2. 使用专门的 init 进程
        docker run -it --init you_docker_image_id

        3. 可通过 shareProcessNamespace 参数为 true 解决

### RS256 jwt 解码
    得到了证书需要用下面命令得到公钥
    openssl x509 -in key.crt -pubkey -noout 
    使用公钥 解析 jwt_token 验证签名的正确性

    openssl rsa -pubin -in JWTSigner-certificate.pem 验证证书的正确性


### nginx配置文件修改， docker restart不生效
    通过 vim 修改宿主 test.txt 文件，但是容器中 test.txt 没有修改

    Linux中，证明文件是否相同的根本途径是，判断其 inode     stat 可以看文件inode值

    vim 修改文件过程：
    1. 复制出一个需要修改文件的副本，命名为在原来文件的基础上增加 ".swp" 后缀以及 "." 前缀。
    2. 修改内容保存到有 .swp 后缀的文件，并 flush 到磁盘
    3. 执行 :wq 就会交换原文件和 swp 文件的名称
    4. 删除临时 swp 文件

    挂载目录，不要挂载文件。挂载目录不会出现宿主机文件更新，而容器中文件没有更新。(推荐此方法)

### 部署 下载地图, 每日更新

    1. 下载地图，和切换地图容器解耦， 一个服务负责下载地图,一个服务负责复制地图,一个服务负责启动容器
    2. 通过 k8s kubectl delete pod 定时重启服务

    难点1. 下载地图与使用地图冲突，且下载地图可能失败：
        通过 下载地图先下到临时文件夹中，下载成功后再替换地图，使用地图从地图中备份一份再使用
    难点2. 启动容器时 备份地图太慢
        通过 cron 定时备份地图到备份名称，启动容器时重命名备份名称的方式解决

    cron 的 $PATH 与linux的$PATH不同
   
### python grpc

    连接rpc服务端, 需要使用证书，
    自签证书若报错域名不被证书认可需要将域名通过下面option重写
    options = (
        (
            'grpc.ssl_target_name_override',
            'localhost',
        ),
    )
    
    周期性的获取 云端数据 fix mongodb

### 一次 多线程/协程 测试

    需求: 请求一个websocket服务, 获取数据（100w条）
    
    一次 websocket 连接， 请求 尽可能多的条数 (避免一次请求建立一次 websocket连接)

    使用python协程 （协程需要一个事件循环，将todo放到事件循环里，这样才能在堵塞时,不浪费cpu轮转到的线程时间片机会。 但是本例中）

    asyncio中的协程就是利用这一概念实现的。asyncio提供的事件循环可以管理协程的调度,当一个协程yield后,事件循环会保存其状态,并调度其他任务。

    async def main():   # 多个协程放入调度器调度才有效果。
        await asyncio.gather(count(), count())


这个例子中， some_func(0) 执行完毕后才会 去执行 some_func(1). 并没有利用到协程优势

    async def some_func(num):
        print(f'Start {num}')
        await asyncio.sleep(1)  # 假设这里有耗时操作
        print(f'End {num}')
        return num

    async def main():
        for i in range(5):
            l = await some_func(i)
            print(f'Result: {l}')

    asyncio.run(main())

这个例子中， asyncio.gather 将加入调度才能获得优势。

    import asyncio

    async def some_func(num):
        print(f'Start {num}')
        await asyncio.sleep(1)  
        print(f'End {num}')

    async def main(): 
        await asyncio.gather(
            some_func(0), 
            some_func(1),
            some_func(2)
        )

    asyncio.run(main())


    线程 + 协程的方式
    在线程中，创建一个事件循环，才能吧async的方法 放进去。

    async def thread_run(n, istart):    # 每个线程跑 10000条数据
        t1 = time.time()
        iend = max(len(lane_ids), istart + 10000)
        await get_lane_info(lane_ids[istart: iend])
        t2 = time.time()
        print(f'线程 {n}: {t2 - t1}')

    def run_count(n, istart):
        print(f'线程 {n} 执行！')
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(thread_run(n, istart))

    # 开启线程
    t = threading.Thread(target=run_count, args=(f"t{i}", i * 10000))
    t.start()

    多线程，加上每个线程 请求后重试设计。