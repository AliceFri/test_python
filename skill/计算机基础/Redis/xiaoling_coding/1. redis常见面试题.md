[//]: # (https://xiaolincoding.com/redis/data_struct/command.html#%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0)


### 1. 什么是 Redis

    Redis 是一种基于内存的数据库，对数据的读写操作都是在内存中完成，因此读写速度非常快，常用于缓存，消息队列、分布式锁等场景。

    Redis 提供了多种数据类型来支持不同的业务场景，比如 String(字符串)、Hash(哈希)、 List (列表)、Set(集合)、Zset(有序集合)、Bitmaps（位图）、
    HyperLogLog（基数统计）、GEO（地理信息）、Stream（流），并且对数据类型的操作都是原子性的。

    Redis 还支持事务 、持久化、Lua 脚本、多种集群方案（主从复制模式、哨兵模式、切片机群模式）、发布/订阅模式，内存淘汰机制、过期删除机制等等。


### 2. Redis 和 Memcached 有什么区别

    共同点：
        1. 都是基于内存的数据库，都可以用来当做缓存
        2. 都有过期策略
        3. 两者的性能都非常高
    区别：
        1. Redis支持更多数据类型（String Hash List Set ZSet）  memcached只支持最简单的key-value数据类型
        2. Redis支持数据的持久化， 而memcached没有持久化功能
        3. Redis原生支持集群模式， Memcached没有原生的集群模式， 需要依赖客户端实现
        4. Redis支持 发布订阅模型， Lua脚本， 事务等功能

### 3. 为什么用Redis作为MySQL的缓存

    因为Redis 具备高性能和高并发两种特性

    1. redis具备高性能
        内存数据库，性能高，查询数据比读mysql快的多

    2. redis具备高并发
        单台设备的redis qps(每秒钟处理请求的次数)是mysql的10倍。


---------------------

### 4. Redis数据类型以及使用场景分别是什么

    String Hash List Set Zset(有序集合)

    String 可以是字符串,整数和浮点数    可以字符串进行操作，可以对整数和浮点数进行自增或自减操作

    List    链表                      两端进行push和pop操作，读取单个或多个元素，根据值查找或删除元素

    Set     包含字符串的无序集合          字符串的集合，判断是否存在，添加，获取，删除；还包含计算交集，并集，差集等

    Hash    包含键值对的无序散列表         添加，获取，删除，判断是否存在等

    Zset    有序集合，其实是字符串和浮点数score的键值对    元素的排列顺序由分数的大小决定，根据分值范围或成员来获取元素

    BitMap, HyperLogLog, GEO, Stream


    应用场景：

    1. String:  缓存对象，常规计数，分布式锁，共享session信息等。
    2. List: 消息队列
    3. Hash: 缓存对象，购物车等
    4. Set: 集合场景， 比如点赞，共同关注，抽奖活动等。
    5. Zset: 排序场景， 排行榜等

    6. BitMap: 二值状态统计，签到等
    7. HyperLogLog: 海量数据基数统计的场景
    8. GEO: 地图信息，附近的人
    9. Stream: 消息队列（自动生成全局唯一消息ID， 支持以消费组形式消费数据）

### 6. Redis底层如何实现的这些数据结构

    String: SDS(简单动态字符串)
        SDS使用len属性的值而不是特殊字符来判断字符串是否结束。
        SDS能存储二进制数据， SDS所有api都是以处理二进制的方式
        SDS获取字符串长度的时间复杂度是O(1),有len属性
        SDS API是安全的，不会有溢出，因为如果空间不够会自动扩容

    List:
        列表元素个数小于512 列表每个元素小于64字节        压缩列表
        双向链表
        
        3.2版本之后， 由quicklist实现

    Hash:
        压缩列表 / 哈希表

        3.2 版本之后，由 listpack 和哈希表实现
    
    Set:
        整数集合 / 哈希表

    Zset:
        压缩列表 / 哈希表

        3.2 版本之后，由 listpack 和跳表实现

--------------------------------

### 7. Redis是单线程吗

    Redis, 接受客户端请求->解析请求->数据操作->返回结果 这个过程是由一个线程(主线程)来完成的

    此外： redis还会有几个线程： 处理关闭文件的线程，AOF刷盘线程， lazyfree线程异步释放Redis内存

    redis为「关闭文件、AOF 刷盘、释放内存」这些耗时的操作单独创建线程，避免主线程堵塞，关闭文件、AOF 刷盘、释放内存这三个任务都有各自的任务队列


    1. 初始化：使用I/O多路复用（epoll）监听客户端连接/请求， epoll_wait等待事件到来
    2. 事件分发： 连接事件 -> 创建连接，添加到epoll, 注册读事件处理函数
                读事件 -> 调用读事件处理函数，将客户端对象添加到发送队列，将结果写到发送缓存区等待发送
                写事件 -> 调用写事件处理函数， 通过 write 函数将客户端发送缓存区里的数据发送出去，如果这一轮数据没有发送完，就会继续注册写事件处理函数，等待 epoll_wait 发现可写后再处理 。


### 8. Redis为什么那么快
    1. 内存数据库，内存访问快
    2. 避免多线程之间的竞争，省去了多线程上下文切换的开销，且避免了加锁，死锁等问题
    3. IO多路复用机制，可以处理大量的Socket请求， 一个线程处理多个IO流
    
### 9. Redis6.0之前为什么使用单线程
    1. cpu并不是制约Redis性能表现的瓶颈所在
    2. 多线程会提高系统复杂度

### 10. Redis6.0之后为什么引入多线程
    1. 在 Redis 6.0 版本之后，也采用了多个 I/O 线程来处理网络请求，这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上。
    2. 但是对于命令的执行，Redis 仍然使用单线程来处理

    Redis 6.0 版本支持的 I/O 多线程特性，默认情况下 I/O 多线程只针对发送响应数据（write client socket），并不会以多线程的方式处理读请求（read client socket）

-------------------------

### Redis持久化

    AOF: 每执行一条写操作命令，就把该命令以追加的方式写到一个文件里
    RDB： 将某一时刻的内存数据，以二进制的方式写入磁盘
    混合持久化（AOF + RDB）

    aof: 先执行写操作命令后，再将命令记录到日志里
        不会阻塞当前命令的执行，但写日志还是会阻塞后续的操作； 数据可能会丢失。但不用担心命令记录了但没有操作。
    
    aof写回策略：  会先写到aof_buf,然后拷贝到内核态的page cache,aof写会策略决定什么时候写入到硬盘
        always:  每次执行命令后，就同步将aof日志写会硬盘
        everysec: 每隔一秒将缓冲区里的内容写回到硬盘
        no: 由操作系统决定

    aof重写机制： aof文件大小超过所设定的阈值后，会触发aof重写。创建新的aof文件。
        aof重写由后台子进程bgrewriteaof来完成， 不会堵塞主线程， 子进程保留副本，不需要给数据加锁。设置aof重写缓冲区记录aof重写期间执行的写操作。

    rdb:
        记录某一瞬间的数据，以二进制的方式写入磁盘
        恢复数据效率更高（直接读入内存）

        save: 同步执行命令，会阻塞主线程
        bgsave: 会创建子进程来生成RDB文件，避免主线程的阻塞

        全量快照，是一个比较重的操作，不应该执行太频繁

        bgsave期间，主线程依旧可以写数据， 使用到了写时复制COW技术。 父子进程指向同一块物理内存，读共享，若有一个进程要写数据，则在另一个进程复制一份数据。达到相互不影响。

### 12. 混合持久化

    RDB： 恢复数据快，但是快照频率不好把握， 频率太低，丢失数据会比较多，频率太高，影响性能
    AOF： 丢失数据少，数据恢复慢

    AOF重写时， 将数据以RDB形式写入到AOF文件，然后加上缓冲区里的AOF命令，

    这样AOF文件的前半部分是RDB格式的全量数据，后半部分是AOF格式的增量数据。

    问题： 版本兼容的问题，和AOF文件可读性会变差的问题。
    
----------------------------------

### 13. Redis集群

#### 13.1 主从复制
    一主多从， 读写分离

    主服务器可以进行读写操作，发生写操作时会自动将写操作同步给从服务器。 从服务器一般是只读，并接受主服务器命令执行。

    无法实现强一致性保证（主从数据时时刻刻保持一致），数据不一致是难以避免的。

#### 13.2 哨兵模式
    主从服务器宕机时如何进行故障转移， 哨兵模式

    哨兵 监控各节点状态，且有故障发现和故障转移的能力。

#### 13.3 切片集群

    分布式， Redis Cluster方案

    一个切片集群共有 16384 个哈希槽， 根据哈希平均分配/手动分配 指定 哈希槽和节点之间的对应关系


#### 13.4 集群脑裂导致数据丢失

    如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的

    哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），
    于是哨兵就会在「从节点」中选举出一个 leader 作为主节点，这时集群就有两个主节点了 —— 脑裂出现了。
    
    然后，网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步

    因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。
    所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题。
    
    解决方案：
    1.  当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。

    等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。
    而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。
    
------------------------------

### 14. Redis过期删除策略

    每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个过期字典（expires dict）中，
    也就是说「过期字典」保存了数据库中所有 key 的过期时间。 
   
    查询key时，如果不在过期字典中则正常读取键值，如果存在则进行时间比对，判断是否过期。

    惰性删除+定期清除
    惰性删除，不主动删除，访问key时判断是否过期，过期时删除key. 优点： 性能高， 缺点： 占用内存
    定期删除，每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。
        随机抽取key, 若删除比例高。则继续删除；并且设置了最长执行时间20ms

    
### 15. 持久化时，对过期键如何处理

    RDB文件生成阶段： 过期的键不会保存到RDB文件中去
    RDB加载阶段： 主服务器会在载入RDB文件时对键进行过期 检查。过期键不会载入。

    AOF写入阶段： 过期键被删除时，会追加一条DEL命令显式的删除该键值
    AOF重写阶段： 已过期的键不会被保存到重写后的 AOF 文件中

### 16. Redis主从模式中，过期键如何处理

    从库不会进行过期扫描，从库对过期的处理是被动的
    主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库

### 17. Redis 内存满了，会发生什么
    
    会触发内存淘汰机制

    1. 不进行内存淘汰， 返回错误
    2.  volatile-randm 随机淘汰设置了过期时间的任意键值
        volatile-ttl 优先淘汰更早过期的键值
        volatile-lru 淘汰设置了过期时间的键值中，最久未使用的键值
        volatile-lfu 淘汰设置了过期时间的键值中，最少使用的键值
        
        allkeys-random: 随机淘汰任意键值
        allkeys-lru
        allkeys-lfu

    lru算法：最近未使用， 常规使用双向链表 + 哈希
        redis实现的是一种近似lru算法，目的是更好的节约内存。它的实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间。
        Redis 进行内存淘汰时，会使用随机采样的方式来淘汰数据，它是随机取 5 个值（此值可配置），然后淘汰最久没有使用的那个。

    lfu算法： 同lru

----------------------------------------------------

### 18. 缓存雪崩 缓存击穿 缓存穿透

#### 18.1 如何避免缓存雪崩
    当大量缓存数据在同一时间过期（失效）时，如果此时有大量的用户请求，都无法在 Redis 中处理，
    于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是缓存雪崩的问题。

    1. 将缓存失效时间随机打散
    2. 设置缓存不过期， 由后台服务负责更新缓存数据

#### 18.2 如何避免缓存击穿

    如果缓存中的某个热点数据过期了，此时大量的请求访问了该热点数据，就无法从缓存中读取，
    直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是缓存击穿的问题。

    1. 互斥锁方案（Redis 中使用 setNX 方法设置一个状态位，表示这是一种锁定状态）， 保证同一时间只有一个业务线程请求缓存
    2. 不给热点数据设置过期时间，或者热点数据准备过期时，提前通知更新缓存和重新设置过期时间

#### 18.3 如何避免缓存穿透
    当用户访问的数据，既不在缓存中，也不在数据库中，导致请求在访问缓存时，发现缓存缺失。

    1. 非法请求的限制
    2. 设置空值或者默认值
    3. 使用布隆过滤器（高效的概率型数据结构,可以用于判断一个元素是否在一个集合中）判断是否数据库中有该数据

### 19. 如何设计一个缓存策略，动态缓存热点数据

    通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据。
    lru lfu. 定期过滤掉队列中排名最后的 200 个商品，然后再从数据库中随机读取出 200 个商品加入队列中；

### 20. 常见的缓存更新策略

    旁路缓存：    写策略： 先更新数据库，再删除缓存
                读策略： 缓存未命中，  读取数据库， 回写缓存

                优化：  更新数据库时也更新缓存，可以考虑加锁或者给缓存加一个较短的过期时间。

    读穿 / 写穿：    先查询缓存中数据是否存在，如果存在则直接返回，如果不存在，则由缓存组件负责从数据库查询数据，并将结果写入到缓存组件，最后缓存组件将数据返回给应用。
                    Read/Write Through（读穿 / 写穿）策略原则是应用程序只和缓存交互，不再和数据库交互，而是由缓存和数据库交互，相当于更新数据库的操作由缓存自己代理了。

    写回：   Write Back 策略特别适合写多的场景
            只更新缓存，同时将缓存数据设置为脏的，然后立马返回，并不会更新数据库。对于数据库的更新，会通过批量异步更新的方式进行。

### 21. 如何保证缓存和数据库数据的一致性

    略

--------------------------------------------------

### 22. Redis实战， Redis如何实现延迟队列

    延迟队列是指把当前要做的事情，往后推迟一段时间再做。延迟队列的常见使用场景有以下几种：
        在淘宝、京东等购物平台上下单，超过一定时间未付款，订单会自动取消；
        点外卖的时候，如果商家在10分钟还没接单，就会自动取消订单；

    可以用Zset 将score设置为时间， zadd添加订单到队列， zrangebyscore取出符合条件的超时订单进行处理。

### 23. Redis的 大key 如何处理

    String 类型的值大于 10 KB；
    Hash、List、Set、ZSet 类型的元素的个数超过 5000个；

    大key的问题：
        1. 操作，删除大key时容易堵塞redis的单线程
        2. 读取大key时流量很大，造成 网络堵塞

    如何找到大key
    1. redis-cli -h 127.0.0.1 -p6379 -a "password" -- bigkeys   最好在从节点上查找或者低峰阶段查找
        这种方法只会返回每种类型中最大的那个bigkey, 根据元素个数判断大小
    2. SCAN命令查找大key
    3. RdbTools工具，解析RDB文件，找到其中的大key  rdb dump.rdb -c memory --byte 10240 -f redis.csv
    
    如何删除大key:
    1. 分批次删除 哈希 hscan 每次获取100个字段， hdel 每次删除1个字段
                列表 ltrim 命令 每次删除少量元素

    2. 异步删除： unlink命令代替del来删除


### 24. Redis管道有什么用

    使用管道技术可以解决多个命令执行时的网络等待，它是把多个命令整合到一起发送给服务器端处理之后统一返回给客户端，
    这样就免去了每条命令执行后都要等待的情况，从而有效地提高了程序的执行效率。

### 25. Redis事务支持回滚吗

    Redis 中并没有提供回滚机制，虽然 Redis 提供了 DISCARD 命令，但是这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。

### 26. 如何用Redis实现分布式锁

    Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：
        如果 key 不存在，则显示插入成功，可以用来表示加锁成功；
        如果 key 存在，则会显示插入失败，可以用来表示加锁失败。

    加锁 SET lock_key unique_value NX PX 10000

    解锁 需要lua脚本保证解锁的原子性， 先判断是否为加锁客户端，再释放锁
    if redis.call("get", KEYS[1]) == ARGV[1] then
        return redis.call("del", KEYS[1])
    else
        return 0

    优点： 1. 性能高效， 实现方便 2. redis集群部署避免单点故障

    缺点：  1. 超时时间不好设置（可以通过续约的方式）
            2. redis主从异步复制，如果主节点宕机会导致分布式锁不可靠。

    为了保证集群环境下分布式锁的可靠性，Redis 官方已经设计了一个分布式锁算法 Redlock（红锁）。
    它是基于多个 Redis 节点的分布式锁，即使有节点发生了故障，锁变量仍然是存在的，客户端还是可以完成锁操作。
    官方推荐是至少部署 5 个 Redis 节点，而且都是主节点，它们之间没有任何关系，都是一个个孤立的节点。

    Redlock 算法的基本思路，是让客户端和多个独立的 Redis 节点依次请求申请加锁，
    如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败。